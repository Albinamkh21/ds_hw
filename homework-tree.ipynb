{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает\n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn (это возможно, так как мы реализуем только малую часть функциональности)\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала так же или качественнее, чем у дерева из sklearn\n",
    "5. Применить реализованное дерево решений для задачи Titanic на kaggle. Применить для той же задачи дерево решений из sklearn. Применить кросс-валидацию для подбора параметров. Сравнить с результатами предыдущих моделей. Если результат улучшился - сделать сабмит. Написать отчет о результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.tree2 = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.max_features = max_features\n",
    "        self.num_class = -1\n",
    "        self.tree_level = 0\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print ('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s,all_count):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        N_l = 1 - pow(l_c/l_s,2).sum(axis=1)\n",
    "        N_r = 1 - pow(r_c/r_s,2).sum(axis=1)\n",
    "        N = sum(all_count) \n",
    "        r = np.transpose((r_s/N).reshape(len(N_r)))*N_r\n",
    "        l = np.transpose((l_s/N).reshape(len(N_l)))*N_l\n",
    "        N_all = 1 - sum(pow(all_count/N,2))\n",
    "        nGain = N_all -  l - r\n",
    "        nGain =  np.around(nGain, decimals=3)   \n",
    "        #print('--gini--')\n",
    "        #print(N_all,r,l,nGain)\n",
    "  \n",
    "        return nGain\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s,all_count):\n",
    "        \n",
    "        N_l = - sum(l_c/l_s*np.log2(l_c/l_s)) \n",
    "        N_r = - sum(r_c/r_s*np.log2(r_c/r_s)) \n",
    "        N = sum(all_count) \n",
    "        nGain = -  l - r\n",
    "        nGain =  np.around(nGain, decimals=3)   \n",
    "        #print('-----')\n",
    "        #print(me_all_mx, r, l,nGain)\n",
    "        return nGain\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s, all_count):\n",
    "        \n",
    "        me_l = 1 - np.amax(l_c/l_s, axis=1) \n",
    "        me_r = 1 - np.amax(r_c/r_s, axis=1) \n",
    "        N = sum(all_count) \n",
    "        me_all = 1 - max(all_count/N)\n",
    "        ones = np.ones(me_r.shape[0]) #нулевая матрица размерность класса\n",
    "        me_all_mx = ones*me_all\n",
    "        r = np.transpose((r_s/N).reshape(len(me_r)))*me_r\n",
    "        l = np.transpose((l_s/N).reshape(len(me_l)))*me_l\n",
    "        nGain = me_all_mx -  l - r\n",
    "        nGain =  np.around(nGain, decimals=3)   \n",
    "        \n",
    "        \n",
    "        return nGain\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = np.arange((n_feature))\n",
    "        fts = shuffle(feature_ids)\n",
    "        num = np.sqrt(n_feature)\n",
    "        return fts[0:int(num)]\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = np.arange((n_feature))\n",
    "        fts = shuffle(feature_ids)\n",
    "        num = np.log(n_feature)\n",
    "        return fts[0:int(num)]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        feature_ids = np.arange((n_feature))\n",
    "        fts= shuffle(feature_ids)\n",
    "        num = len(fts)\n",
    "        return fts[0:int(num)]\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        #left_mask = x > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "    \n",
    "    def __find_depth(self, node_id):    \n",
    "        if node_id < 0:\n",
    "            return -1\n",
    "        if node_id == 0:\n",
    "            return 0\n",
    "        node = self.tree2[node_id]\n",
    "        parentId = node['parentId']\n",
    "        depth = 1\n",
    "        while parentId != 0:\n",
    "            node =  self.tree2[parentId]\n",
    "            parentId = node['parentId']\n",
    "            depth +=1\n",
    "        return depth\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода?\n",
    "        #  Сортирует исходные данные по количественному признаку, для нахождения порогов\n",
    "        #  находит количество уникальных классов\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        num_class = np.unique(y).size\n",
    "   \n",
    "        # Что делает этот блок кода?\n",
    "        # выбирает min_samples_split элементов с обоих концов, те центральных min_samples_split\n",
    "        splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "        #находит индексы, на которых происходит смена класса\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "     \n",
    "        if len(r_border_ids) == 0:\n",
    "            return float('+inf'), None\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        #Строит матрицу возможных разбиений узла, каждая срока представляет собой количество элементов, каждого класса\n",
    "        # матрица нужна для расчета информативности каждого разбиения\n",
    "        eq_el_count = r_border_ids - np.append([self.min_samples_split], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], num_class)) #нулевая матрица размерность класса\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:self.min_samples_split], minlength=num_class)\n",
    "     \n",
    "        # Что делает этот блок кода?\n",
    "        # строит матрицы размерностью n на m, где m - количество уникальных классов.Каждая строка содержит\n",
    "        # количество представительей каждого класса, при каждом разбиении\n",
    "        all_class_count = np.bincount(y)\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)  \n",
    "        r_class_count = all_class_count - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "        \n",
    "       \n",
    "        #Расчет информативности \n",
    "        # Что делает этот блок кода?\n",
    "        # определяет матрицу прироста информации для каждого разбиения\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes,all_class_count )\n",
    "        idx = np.argmin(gs)\n",
    "        #print('-gs, idx-')\n",
    "        #print(gs, idx)\n",
    "        \n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # Возвращает выбраннную информативность\n",
    "        # и Определяет порог(условие), по которому будет происходить разбиение данных  \n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        \n",
    "        \n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1, prev='', parentId =-1):\n",
    "        #print('----------FIT_NODE-------')\n",
    "        #print(len(x))\n",
    "        if len(x) <= 5:\n",
    "            self.tree2[node_id] = {'type':self.__class__.LEAF_TYPE} \n",
    "            prev ='right'\n",
    "        \n",
    "        else:\n",
    "            self.nums = len(x)\n",
    "            # Ваш код\n",
    "           # self.sufficient_share\n",
    "            \n",
    "            self.max_features = self.max_features or x.shape[1]\n",
    "            feature_ids = self.get_feature_ids(self.max_features); \n",
    "            threshold_total = dict()\n",
    "            for f_id in feature_ids:\n",
    "                x_cl = x[:,f_id]\n",
    "                threshold_total[f_id] = self.__find_threshold(x_cl,y)\n",
    "            #print(threshold_total)    \n",
    "            feature_idx = min(threshold_total, key=threshold_total.get)\n",
    "            threshold = threshold_total[feature_idx]\n",
    "            if threshold[1] == None: \n",
    "                self.tree[node_id] = {'level':0,'type':self.__class__.LEAF_TYPE, 'feature_id':feature_idx, 'threshold':threshold[1], 'left_x': x, 'right_x': {}, 'left_y': y, 'right_y': {}} \n",
    "                self.tree2[node_id] = {'level':0,'type':self.__class__.LEAF_TYPE, 'feature_id':feature_idx, 'threshold':threshold[1], 'left_x': len(x), 'right_x': 0, 'parentId':parentId} \n",
    "                prev ='right'\n",
    "            else:\n",
    "                node = self.__div_samples(x,y,feature_idx,threshold[1])\n",
    "                self.tree[node_id] = {'level':0, 'type':self.__class__.NON_LEAF_TYPE, 'feature_id':feature_idx, 'threshold':threshold[1], 'left_x': node[0], 'right_x': node[1], 'left_y': node[2], 'right_y': node[3]} \n",
    "                self.tree2[node_id] = {'level':0, 'type':self.__class__.NON_LEAF_TYPE, 'feature_id':feature_idx, 'threshold':threshold[1], 'left_x': len(node[0]), 'right_x': len(node[1]),'parentId':parentId} \n",
    "            #нужно ли запускать дальше \n",
    "            depth = self.__find_depth(node_id)\n",
    "            if self.max_depth != None and depth >= self.max_depth:\n",
    "                return 0\n",
    "            node_id += 1\n",
    "            if prev == '' or prev == 'right':\n",
    "                prev = 'left'\n",
    "                parentId = parentId + 1\n",
    "                self.__fit_node(self.tree[parentId]['left_x'],self.tree[parentId]['left_y'], node_id,0,pred_f,'left',parentId)\n",
    "\n",
    "            elif prev == 'left' :\n",
    "                prev= 'right'\n",
    "                self.__fit_node(self.tree[parentId]['right_x'],self.tree[parentId]['right_y'], node_id,0,pred_f,'right',parentId)\n",
    "        return 1\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "        print(self.tree2)\n",
    "        return self.tree2\n",
    "        \n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree2[node_id]\n",
    "        if node['type'] == self.__class__.NON_LEAF_TYPE and (2 * node_id + 1) <= max(self.tree):\n",
    "            feature_id = node['feature_id']\n",
    "            threshold = node['threshold']\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return self.tree2[node_id]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1]]), array([1, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data[:90]\n",
    "Y = iris.target[:90]\n",
    "X_test = iris.data[97:99]\n",
    "Y_test = iris.target[97:99]\n",
    "X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'level': 0, 'type': 0, 'feature_id': 1, 'threshold': 2.3499999999999996, 'left_x': 84, 'right_x': 6, 'parentId': -1}, 1: {'level': 0, 'type': 0, 'feature_id': 0, 'threshold': 4.9, 'left_x': 64, 'right_x': 20, 'parentId': 0}, 2: {'level': 0, 'type': 0, 'feature_id': 1, 'threshold': 2.25, 'left_x': 3, 'right_x': 3, 'parentId': 0}, 3: {'level': 0, 'type': 0, 'feature_id': 0, 'threshold': 5.65, 'left_x': 28, 'right_x': 36, 'parentId': 1}, 4: {'level': 0, 'type': 1, 'feature_id': 1, 'threshold': None, 'left_x': 20, 'right_x': 0, 'parentId': 1}, 5: {'type': 1}}\n"
     ]
    }
   ],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2,criterion='gini', max_depth = 4)\n",
    "tree = my_clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'level': 0, 'type': 0, 'feature_id': 0, 'threshold': 5.65, 'left_x': 28, 'right_x': 36, 'parentId': 1},\n",
       "       {'level': 0, 'type': 0, 'feature_id': 0, 'threshold': 5.65, 'left_x': 28, 'right_x': 36, 'parentId': 1}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = my_clf.predict(X_test)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120269, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('e:\\DS\\ds_hw\\cs_training.csv', sep=',').dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X = df.as_matrix(columns=df.columns[1:])\n",
    "Y = df.as_matrix(columns=df.columns[:1])\n",
    "Y = Y.reshape(Y.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'level': 0, 'type': 0, 'feature_id': 8, 'threshold': 0.0, 'left_x': 1971, 'right_x': 71106, 'parentId': 7},\n",
       "       {'level': 0, 'type': 0, 'feature_id': 8, 'threshold': 0.0, 'left_x': 1971, 'right_x': 71106, 'parentId': 7},\n",
       "       {'level': 0, 'type': 0, 'feature_id': 8, 'threshold': 0.0, 'left_x': 1971, 'right_x': 71106, 'parentId': 7},\n",
       "       ...,\n",
       "       {'level': 0, 'type': 0, 'feature_id': 8, 'threshold': 0.0, 'left_x': 1971, 'right_x': 71106, 'parentId': 7},\n",
       "       {'level': 0, 'type': 0, 'feature_id': 5, 'threshold': 0.0, 'left_x': 30, 'right_x': 19, 'parentId': 10},\n",
       "       {'level': 0, 'type': 0, 'feature_id': 8, 'threshold': 0.0, 'left_x': 1971, 'right_x': 71106, 'parentId': 7}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2,criterion='gini')\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'level': 0, 'type': 0, 'feature_id': 2, 'threshold': 0.0, 'left_x': 20299, 'right_x': 99970, 'parentId': -1}, 1: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 20103, 'right_x': 196, 'parentId': 0}, 2: {'level': 0, 'type': 0, 'feature_id': 2, 'threshold': 0.0, 'left_x': 0, 'right_x': 99970, 'parentId': 0}, 3: {'level': 0, 'type': 0, 'feature_id': 8, 'threshold': 0.0, 'left_x': 3600, 'right_x': 16503, 'parentId': 1}, 4: {'level': 0, 'type': 0, 'feature_id': 7, 'threshold': 0.0, 'left_x': 100, 'right_x': 96, 'parentId': 1}, 5: {'type': 1}, 6: {'level': 0, 'type': 0, 'feature_id': 8, 'threshold': 0.0, 'left_x': 18, 'right_x': 1079, 'parentId': 2}, 7: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 5828, 'right_x': 46, 'parentId': 3}, 8: {'level': 0, 'type': 0, 'feature_id': 6, 'threshold': 0.0, 'left_x': 4108, 'right_x': 101022, 'parentId': 3}, 9: {'level': 0, 'type': 0, 'feature_id': 2, 'threshold': 0.0, 'left_x': 63, 'right_x': 367, 'parentId': 4}, 10: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 915, 'right_x': 49, 'parentId': 4}, 11: {'level': 0, 'type': 0, 'feature_id': 0, 'threshold': 0.0, 'left_x': 0, 'right_x': 225, 'parentId': 5}, 12: {'level': 0, 'type': 0, 'feature_id': 6, 'threshold': 0.0, 'left_x': 186, 'right_x': 6363, 'parentId': 5}, 13: {'level': 0, 'type': 0, 'feature_id': 3, 'threshold': 0.0, 'left_x': 0, 'right_x': 18, 'parentId': 6}, 14: {'level': 0, 'type': 0, 'feature_id': 8, 'threshold': 0.0, 'left_x': 0, 'right_x': 1079, 'parentId': 6}, 15: {'level': 0, 'type': 0, 'feature_id': 5, 'threshold': 0.0, 'left_x': 5758, 'right_x': 70, 'parentId': 7}, 16: {'level': 0, 'type': 0, 'feature_id': 7, 'threshold': 0.0, 'left_x': 20, 'right_x': 26, 'parentId': 7}, 17: {'level': 0, 'type': 0, 'feature_id': 8, 'threshold': 0.0, 'left_x': 0, 'right_x': 4108, 'parentId': 8}, 18: {'level': 0, 'type': 0, 'feature_id': 5, 'threshold': 0.0, 'left_x': 100799, 'right_x': 223, 'parentId': 8}, 19: {'level': 0, 'type': 0, 'feature_id': 7, 'threshold': 0.0, 'left_x': 0, 'right_x': 63, 'parentId': 9}, 20: {'level': 0, 'type': 0, 'feature_id': 6, 'threshold': 0.0, 'left_x': 93, 'right_x': 274, 'parentId': 9}, 21: {'level': 0, 'type': 0, 'feature_id': 9, 'threshold': 0.0, 'left_x': 0, 'right_x': 915, 'parentId': 10}, 22: {'level': 0, 'type': 0, 'feature_id': 5, 'threshold': 0.0, 'left_x': 30, 'right_x': 19, 'parentId': 10}, 23: {'type': 1}}\n",
      "0.36402082443237305\n",
      "1.336076259613037\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "my_clf.fit(X, Y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "\n",
    "t1 = time()\n",
    "clf.fit(X, Y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применить для задачи Titanic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"e:/DS/ds_hw/titanic/train.csv\", sep=',').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "1             2         1       1   \n",
       "3             4         1       1   \n",
       "6             7         0       1   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "\n",
       "    Parch    Ticket     Fare Cabin Embarked  \n",
       "1       0  PC 17599  71.2833   C85        C  \n",
       "3       0    113803  53.1000  C123        S  \n",
       "6       0     17463  51.8625   E46        S  \n",
       "10      1   PP 9549  16.7000    G6        S  \n",
       "11      0    113783  26.5500  C103        S  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iSex'] = np.where(df['Sex']=='male', 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Survived', 'Pclass', 'iSex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X = df.as_matrix(columns=df.columns[1:])\n",
    "Y = df.as_matrix(columns=df.columns[:1])\n",
    "Y = Y.reshape(Y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2,criterion='gini', max_depth = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'level': 0, 'type': 0, 'feature_id': 3, 'threshold': 0.0, 'left_x': 73, 'right_x': 110, 'parentId': -1}, 1: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 30, 'right_x': 43, 'parentId': 0}, 2: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 31, 'right_x': 79, 'parentId': 0}, 3: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 1.0, 'left_x': 13, 'right_x': 17, 'parentId': 1}, 4: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 0, 'right_x': 43, 'parentId': 1}, 5: {'level': 0, 'type': 0, 'feature_id': 1, 'threshold': 1.0, 'left_x': 0, 'right_x': 31, 'parentId': 2}, 6: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 0, 'right_x': 79, 'parentId': 2}, 7: {'level': 0, 'type': 0, 'feature_id': 3, 'threshold': 2.5, 'left_x': 3, 'right_x': 10, 'parentId': 3}, 8: {'level': 0, 'type': 0, 'feature_id': 0, 'threshold': 1.0, 'left_x': 6, 'right_x': 11, 'parentId': 3}, 9: {'type': 1}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'level': 0,\n",
       "  'type': 0,\n",
       "  'feature_id': 3,\n",
       "  'threshold': 0.0,\n",
       "  'left_x': 73,\n",
       "  'right_x': 110,\n",
       "  'parentId': -1},\n",
       " 1: {'level': 0,\n",
       "  'type': 0,\n",
       "  'feature_id': 4,\n",
       "  'threshold': 0.0,\n",
       "  'left_x': 30,\n",
       "  'right_x': 43,\n",
       "  'parentId': 0},\n",
       " 2: {'level': 0,\n",
       "  'type': 0,\n",
       "  'feature_id': 4,\n",
       "  'threshold': 0.0,\n",
       "  'left_x': 31,\n",
       "  'right_x': 79,\n",
       "  'parentId': 0},\n",
       " 3: {'level': 0,\n",
       "  'type': 0,\n",
       "  'feature_id': 4,\n",
       "  'threshold': 1.0,\n",
       "  'left_x': 13,\n",
       "  'right_x': 17,\n",
       "  'parentId': 1},\n",
       " 4: {'level': 0,\n",
       "  'type': 0,\n",
       "  'feature_id': 4,\n",
       "  'threshold': 0.0,\n",
       "  'left_x': 0,\n",
       "  'right_x': 43,\n",
       "  'parentId': 1},\n",
       " 5: {'level': 0,\n",
       "  'type': 0,\n",
       "  'feature_id': 1,\n",
       "  'threshold': 1.0,\n",
       "  'left_x': 0,\n",
       "  'right_x': 31,\n",
       "  'parentId': 2},\n",
       " 6: {'level': 0,\n",
       "  'type': 0,\n",
       "  'feature_id': 4,\n",
       "  'threshold': 0.0,\n",
       "  'left_x': 0,\n",
       "  'right_x': 79,\n",
       "  'parentId': 2},\n",
       " 7: {'level': 0,\n",
       "  'type': 0,\n",
       "  'feature_id': 3,\n",
       "  'threshold': 2.5,\n",
       "  'left_x': 3,\n",
       "  'right_x': 10,\n",
       "  'parentId': 3},\n",
       " 8: {'level': 0,\n",
       "  'type': 0,\n",
       "  'feature_id': 0,\n",
       "  'threshold': 1.0,\n",
       "  'left_x': 6,\n",
       "  'right_x': 11,\n",
       "  'parentId': 3},\n",
       " 9: {'type': 1}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
