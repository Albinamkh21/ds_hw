{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает\n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn (это возможно, так как мы реализуем только малую часть функциональности)\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала так же или качественнее, чем у дерева из sklearn\n",
    "5. Применить реализованное дерево решений для задачи Titanic на kaggle. Применить для той же задачи дерево решений из sklearn. Применить кросс-валидацию для подбора параметров. Сравнить с результатами предыдущих моделей. Если результат улучшился - сделать сабмит. Написать отчет о результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.tree2 = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.max_features = max_features\n",
    "        self.num_class = -1\n",
    "        self.tree_level = 0\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print ('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s,all_count):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        N_l = 1 - pow(l_c/l_s,2).sum(axis=1)\n",
    "        N_r = 1 - pow(r_c/r_s,2).sum(axis=1)\n",
    "        N = sum(all_count) \n",
    "        r = np.transpose((r_s/N).reshape(len(N_r)))*N_r\n",
    "        l = np.transpose((l_s/N).reshape(len(N_l)))*N_l\n",
    "        N_all = 1 - sum(pow(all_count/N,2))\n",
    "        nGain = N_all -  l - r\n",
    "        nGain =  np.around(nGain, decimals=3)   \n",
    "        #print('--gini--')\n",
    "        #print(N_all,r,l,nGain)\n",
    "  \n",
    "        return nGain\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s,all_count):\n",
    "        \n",
    "        N_l = - sum(l_c/l_s*np.log2(l_c/l_s)) \n",
    "        N_r = - sum(r_c/r_s*np.log2(r_c/r_s)) \n",
    "        N = sum(all_count) \n",
    "        nGain = -  l - r\n",
    "        nGain =  np.around(nGain, decimals=3)   \n",
    "        #print('-----')\n",
    "        #print(me_all_mx, r, l,nGain)\n",
    "        return nGain\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s, all_count):\n",
    "        \n",
    "        me_l = 1 - np.amax(l_c/l_s, axis=1) \n",
    "        me_r = 1 - np.amax(r_c/r_s, axis=1) \n",
    "        N = sum(all_count) \n",
    "        me_all = 1 - max(all_count/N)\n",
    "        ones = np.ones(me_r.shape[0]) #нулевая матрица размерность класса\n",
    "        me_all_mx = ones*me_all\n",
    "        r = np.transpose((r_s/N).reshape(len(me_r)))*me_r\n",
    "        l = np.transpose((l_s/N).reshape(len(me_l)))*me_l\n",
    "        nGain = me_all_mx -  l - r\n",
    "        nGain =  np.around(nGain, decimals=3)   \n",
    "        \n",
    "        \n",
    "        return nGain\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = np.arange((n_feature))\n",
    "        fts = shuffle(feature_ids)\n",
    "        num = np.sqrt(n_feature)\n",
    "        return fts[0:int(num)]\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = np.arange((n_feature))\n",
    "        fts = shuffle(feature_ids)\n",
    "        num = np.log(n_feature)\n",
    "        return fts[0:int(num)]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        feature_ids = np.arange((n_feature))\n",
    "        fts= shuffle(feature_ids)\n",
    "        num = len(fts)\n",
    "        return fts[0:int(num)]\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        #left_mask = x > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "    \n",
    "    def __find_depth(self, node_id):    \n",
    "        if node_id < 0:\n",
    "            return -1\n",
    "        if node_id == 0:\n",
    "            return 0\n",
    "        node = self.tree2[node_id]\n",
    "        parentId = node['parentId']\n",
    "        depth = 1\n",
    "        while parentId != 0:\n",
    "            node =  self.tree2[parentId]\n",
    "            parentId = node['parentId']\n",
    "            depth +=1\n",
    "        return depth\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода?\n",
    "        #  Сортирует исходные данные по количественному признаку, для нахождения порогов\n",
    "        #  находит количество уникальных классов\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        num_class = np.unique(y).size\n",
    "   \n",
    "        # Что делает этот блок кода?\n",
    "        # выбирает min_samples_split элементов с обоих концов, те центральных min_samples_split\n",
    "        splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "        #находит индексы, на которых происходит смена класса\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "     \n",
    "        if len(r_border_ids) == 0:\n",
    "            return float('+inf'), None\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        #Строит матрицу возможных разбиений узла, каждая срока представляет собой количество элементов, каждого класса\n",
    "        # матрица нужна для расчета информативности каждого разбиения\n",
    "        eq_el_count = r_border_ids - np.append([self.min_samples_split], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], num_class)) #нулевая матрица размерность класса\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:self.min_samples_split], minlength=num_class)\n",
    "     \n",
    "        # Что делает этот блок кода?\n",
    "        # строит матрицы размерностью n на m, где m - количество уникальных классов.Каждая строка содержит\n",
    "        # количество представительей каждого класса, при каждом разбиении\n",
    "        all_class_count = np.bincount(y)\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)  \n",
    "        r_class_count = all_class_count - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "        \n",
    "       \n",
    "        #Расчет информативности \n",
    "        # Что делает этот блок кода?\n",
    "        # определяет матрицу прироста информации для каждого разбиения\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes,all_class_count )\n",
    "        idx = np.argmin(gs)\n",
    "        #print('-gs, idx-')\n",
    "        #print(gs, idx)\n",
    "        \n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # Возвращает выбраннную информативность\n",
    "        # и Определяет порог(условие), по которому будет происходить разбиение данных  \n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        \n",
    "        \n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1, prev='', parentId =-1):\n",
    "        #print('----------FIT_NODE-------')\n",
    "        #print(len(x))\n",
    "        if len(x) <= 5:\n",
    "            self.tree2[node_id] = {'type':self.__class__.LEAF_TYPE} \n",
    "            prev ='right'\n",
    "        \n",
    "        else:\n",
    "            self.nums = len(x)\n",
    "            # Ваш код\n",
    "           # self.sufficient_share\n",
    "            \n",
    "            self.max_features = self.max_features or x.shape[1]\n",
    "            feature_ids = self.get_feature_ids(self.max_features); \n",
    "            threshold_total = dict()\n",
    "            for f_id in feature_ids:\n",
    "                x_cl = x[:,f_id]\n",
    "                threshold_total[f_id] = self.__find_threshold(x_cl,y)\n",
    "            #print(threshold_total)    \n",
    "            feature_idx = min(threshold_total, key=threshold_total.get)\n",
    "            threshold = threshold_total[feature_idx]\n",
    "            if threshold[1] == None: \n",
    "                self.tree[node_id] = {'level':0,'type':self.__class__.LEAF_TYPE, 'feature_id':feature_idx, 'threshold':threshold[1], 'left_x': x, 'right_x': {}, 'left_y': y, 'right_y': {}} \n",
    "                self.tree2[node_id] = {'level':0,'type':self.__class__.LEAF_TYPE, 'feature_id':feature_idx, 'threshold':threshold[1], 'left_x': len(x), 'right_x': 0, 'parentId':parentId} \n",
    "                prev ='right'\n",
    "            else:\n",
    "                node = self.__div_samples(x,y,feature_idx,threshold[1])\n",
    "                self.tree[node_id] = {'level':0, 'type':self.__class__.NON_LEAF_TYPE, 'feature_id':feature_idx, 'threshold':threshold[1], 'left_x': node[0], 'right_x': node[1], 'left_y': node[2], 'right_y': node[3]} \n",
    "                self.tree2[node_id] = {'level':0, 'type':self.__class__.NON_LEAF_TYPE, 'feature_id':feature_idx, 'threshold':threshold[1], 'left_x': len(node[0]), 'right_x': len(node[1]),'parentId':parentId} \n",
    "            #нужно ли запускать дальше \n",
    "            depth = self.__find_depth(node_id)\n",
    "            if self.max_depth != None and depth >= self.max_depth:\n",
    "                return 0\n",
    "            node_id += 1\n",
    "            if prev == '' or prev == 'right':\n",
    "                prev = 'left'\n",
    "                parentId = parentId + 1\n",
    "                self.__fit_node(self.tree[parentId]['left_x'],self.tree[parentId]['left_y'], node_id,0,pred_f,'left',parentId)\n",
    "\n",
    "            elif prev == 'left' :\n",
    "                prev= 'right'\n",
    "                self.__fit_node(self.tree[parentId]['right_x'],self.tree[parentId]['right_y'], node_id,0,pred_f,'right',parentId)\n",
    "        return 1\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "        print(self.tree2)\n",
    "        return self.tree2\n",
    "        \n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree2[node_id]\n",
    "        if node['type'] == self.__class__.NON_LEAF_TYPE and (2 * node_id + 1) <= max(self.tree):\n",
    "            feature_id = node['feature_id']\n",
    "            threshold = node['threshold']\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return self.tree2[node_id]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1]]), array([1, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data[:90]\n",
    "Y = iris.target[:90]\n",
    "X_test = iris.data[97:99]\n",
    "Y_test = iris.target[97:99]\n",
    "X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'level': 0, 'type': 0, 'feature_id': 1, 'threshold': 2.3499999999999996, 'left_x': 84, 'right_x': 6, 'parentId': -1}, 1: {'level': 0, 'type': 0, 'feature_id': 0, 'threshold': 4.9, 'left_x': 64, 'right_x': 20, 'parentId': 0}, 2: {'level': 0, 'type': 0, 'feature_id': 1, 'threshold': 2.25, 'left_x': 3, 'right_x': 3, 'parentId': 0}, 3: {'level': 0, 'type': 0, 'feature_id': 0, 'threshold': 5.65, 'left_x': 28, 'right_x': 36, 'parentId': 1}, 4: {'level': 0, 'type': 1, 'feature_id': 0, 'threshold': None, 'left_x': 20, 'right_x': 0, 'parentId': 1}, 5: {'type': 1}}\n"
     ]
    }
   ],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2,criterion='gini', max_depth = 4)\n",
    "tree = my_clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'level': 0, 'type': 0, 'feature_id': 0, 'threshold': 5.65, 'left_x': 28, 'right_x': 36, 'parentId': 1},\n",
       "       {'level': 0, 'type': 0, 'feature_id': 0, 'threshold': 5.65, 'left_x': 28, 'right_x': 36, 'parentId': 1}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = my_clf.predict(X_test)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120269, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('e:\\DS\\ds_hw\\cs_training.csv', sep=',').dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X = df.as_matrix(columns=df.columns[1:])\n",
    "Y = df.as_matrix(columns=df.columns[:1])\n",
    "Y = Y.reshape(Y.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2,criterion='gini')\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'level': 0, 'type': 0, 'feature_id': 9, 'threshold': 0.0, 'left_x': 54813, 'right_x': 65456, 'parentId': -1}, 1: {'level': 0, 'type': 0, 'feature_id': 2, 'threshold': 0.0, 'left_x': 10601, 'right_x': 44212, 'parentId': 0}, 2: {'level': 0, 'type': 0, 'feature_id': 7, 'threshold': 0.0, 'left_x': 37311, 'right_x': 28145, 'parentId': 0}, 3: {'level': 0, 'type': 0, 'feature_id': 8, 'threshold': 0.0, 'left_x': 1941, 'right_x': 8660, 'parentId': 1}, 4: {'level': 0, 'type': 0, 'feature_id': 7, 'threshold': 0.0, 'left_x': 32114, 'right_x': 12098, 'parentId': 1}, 5: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 36885, 'right_x': 426, 'parentId': 2}, 6: {'level': 0, 'type': 0, 'feature_id': 7, 'threshold': 0.0, 'left_x': 0, 'right_x': 28145, 'parentId': 2}, 7: {'level': 0, 'type': 0, 'feature_id': 3, 'threshold': 0.0, 'left_x': 1901, 'right_x': 40, 'parentId': 3}, 8: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 8592, 'right_x': 68, 'parentId': 3}, 9: {'level': 0, 'type': 0, 'feature_id': 6, 'threshold': 0.0, 'left_x': 635, 'right_x': 31479, 'parentId': 4}, 10: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 11929, 'right_x': 169, 'parentId': 4}, 11: {'level': 0, 'type': 0, 'feature_id': 8, 'threshold': 0.0, 'left_x': 1439, 'right_x': 35446, 'parentId': 5}, 12: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 0, 'right_x': 426, 'parentId': 5}, 13: {'type': 1}}\n",
      "0.5750329494476318\n",
      "1.2770731449127197\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "my_clf.fit(X, Y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "\n",
    "t1 = time()\n",
    "clf.fit(X, Y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'level': 0, 'type': 0, 'feature_id': 8, 'threshold': 0.0, 'left_x': 4994, 'right_x': 91221, 'parentId': -1}, 1: {'level': 0, 'type': 0, 'feature_id': 3, 'threshold': 0.0, 'left_x': 4857, 'right_x': 137, 'parentId': 0}, 2: {'level': 0, 'type': 0, 'feature_id': 6, 'threshold': 0.0, 'left_x': 3624, 'right_x': 87597, 'parentId': 0}, 3: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 4820, 'right_x': 37, 'parentId': 1}, 4: {'level': 0, 'type': 0, 'feature_id': 3, 'threshold': 0.0, 'left_x': 0, 'right_x': 137, 'parentId': 1}, 5: {'level': 0, 'type': 0, 'feature_id': 5, 'threshold': 0.0, 'left_x': 3356, 'right_x': 268, 'parentId': 2}, 6: {'level': 0, 'type': 0, 'feature_id': 3, 'threshold': 0.0, 'left_x': 85913, 'right_x': 1684, 'parentId': 2}, 7: {'level': 0, 'type': 0, 'feature_id': 2, 'threshold': 0.0, 'left_x': 2737, 'right_x': 2083, 'parentId': 3}, 8: {'level': 0, 'type': 0, 'feature_id': 4, 'threshold': 0.0, 'left_x': 0, 'right_x': 37, 'parentId': 3}, 9: {'type': 1}, 10: {'level': 0, 'type': 0, 'feature_id': 0, 'threshold': 0.0, 'left_x': 0, 'right_x': 71, 'parentId': 4}, 11: {'level': 0, 'type': 0, 'feature_id': 7, 'threshold': 0.0, 'left_x': 1342, 'right_x': 1259, 'parentId': 5}, 12: {'level': 0, 'type': 0, 'feature_id': 2, 'threshold': 0.0, 'left_x': 0, 'right_x': 39, 'parentId': 5}, 13: {'type': 1}}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "accuracy_score() got an unexpected keyword argument 'Y_true'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-1d5042f64c8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmy_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: accuracy_score() got an unexpected keyword argument 'Y_true'"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(X, Y):\n",
    "    X_train, Y_train = X[train], Y[train]\n",
    "    X_test, Y_test = X[test], Y[test]\n",
    "    my_clf.fit(X_train, Y_train)\n",
    "        print(accuracy_score(y_pred=clf.predict(X_test), Y_true=Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применить для задачи Titanic "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
